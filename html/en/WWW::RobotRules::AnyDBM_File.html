<html>
<head><meta charset=utf-8/>
<title>WWW::RobotRules::AnyDBM_File - Persistent RobotRules</title></head>
<body><pre>

WWW::RobotRules::AnyDBMUsereContributed Perl DoWWW::RobotRules::AnyDBM_File(3pm)



NAME
       WWW::RobotRules::AnyDBM_File - Persistent RobotRules

SYNOPSIS
        require WWW::RobotRules::AnyDBM_File;
        require LWP::RobotUA;

        # Create a robot useragent that uses a diskcaching RobotRules
        my $rules = WWW::RobotRules::AnyDBM_File-&gt;new( &apos;my-robot/1.0&apos;, &apos;cachefile&apos; );
        my $ua = WWW::RobotUA-&gt;new( &apos;my-robot/1.0&apos;, &apos;me@foo.com&apos;, $rules );

        # Then just use $ua as usual
        $res = $ua-&gt;request($req);

DESCRIPTION
       This is a subclass of WWW::RobotRules that uses the AnyDBM_File package
       to implement persistent diskcaching of robots.txt and host visit
       information.

       The constructor (the new() method) takes an extra argument specifying the
       name of the DBM file to use.  If the DBM file already exists, then you
       can specify undef as agent name as the name can be obtained from the DBM
       database.

SEE ALSO
       WWW::RobotRules, LWP::RobotUA

AUTHORS
       Hakan Ardo &lt;hakan@munin.ub2.lu.se&gt;, Gisle Aas &lt;aas@sn.no&gt;



perl v5.10.1                       2011-03-13  WWW::RobotRules::AnyDBM_File(3pm)

</pre></body></html>
